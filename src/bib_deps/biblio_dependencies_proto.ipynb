{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TexSoup import TexSoup\n",
    "from TexSoup.data import TexNode, BraceGroup\n",
    "import csv\n",
    "import os\n",
    "from typing import Literal, TypeAlias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '../../data/dot.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class INBibEntry:\n",
    "    id: str\n",
    "    bibkey: str\n",
    "    title: str\n",
    "    notes: str\n",
    "    crossref: str\n",
    "    further_note: str\n",
    "\n",
    "@dataclass\n",
    "class ParsedBibEntry(INBibEntry):\n",
    "    further_references_raw: list[str]\n",
    "    depends_on_raw: list[str]\n",
    "\n",
    "@dataclass\n",
    "class ProcessedBibEntry(INBibEntry):\n",
    "    further_references_good: list[str]\n",
    "    further_references_bad: list[str]\n",
    "    depends_on_good: list[str]\n",
    "    depends_on_bad: list[str]\n",
    "\n",
    "\n",
    "CitetField: TypeAlias = Literal[\n",
    "    # For further_references\n",
    "    \"title\",\n",
    "    \"notes\",\n",
    "    # for depends_on\n",
    "    \"crossref\",\n",
    "    \"further_note\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bibentries_csv(filename: str, encoding: str) -> list[INBibEntry]:\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"File '{filename}' not found\")\n",
    "\n",
    "    with open(filename, 'r', encoding=encoding) as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        rows = [\n",
    "            INBibEntry(\n",
    "                id=row['id'],\n",
    "                bibkey=row['bibkey'],\n",
    "                title=row['title'],\n",
    "                notes=row['notes'],\n",
    "                crossref=row['crossref'],\n",
    "                further_note=row['further_note'],\n",
    "            )\n",
    "            for row in csv_reader\n",
    "        ]\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citet_bibkeys(row: INBibEntry, citet_field: CitetField) -> list[str]:\n",
    "    data = getattr(row, citet_field)\n",
    "    citet_l = TexSoup(data).find_all('citet')\n",
    "    citets_raw_nested = [citet.args for citet in citet_l if isinstance(citet, TexNode)]\n",
    "    citets_raw_flat = [item for sublist in citets_raw_nested for item in sublist]\n",
    "    citets_s = [citet.string.split(\",\") for citet in citets_raw_flat if isinstance(citet, BraceGroup)]\n",
    "    citets_s_flat = [item.strip() for sublist in citets_s for item in sublist]\n",
    "\n",
    "    return citets_s_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = load_bibentries_csv(test_file, 'utf-16')\n",
    "res = [(row.id, get_citet_bibkeys(row, \"notes\")) for row in rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('163608', ['russell_b:1905']),\n",
       " ('62997',\n",
       "  ['frege:1882',\n",
       "   'frege:1891',\n",
       "   'frege:1892',\n",
       "   'frege:1892a',\n",
       "   'frege:1918',\n",
       "   'frege:1923',\n",
       "   'frege:1918a']),\n",
       " ('7445', ['austin_jl:1961']),\n",
       " ('172159', ['sen_a:1987']),\n",
       " ('72443', ['rodislewis:1987']),\n",
       " ('184232', ['strawson_pf:1971']),\n",
       " ('78074', ['apt:1985', 'bibkey:test123'])]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in res if item[1] != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bibentry(row: INBibEntry) -> ParsedBibEntry:\n",
    "    notes_bibkeys = get_citet_bibkeys(row, \"notes\")\n",
    "    title_bibkeys = get_citet_bibkeys(row, \"title\")\n",
    "    \n",
    "    further_references_raw = notes_bibkeys + title_bibkeys\n",
    "\n",
    "    further_notes_bibkeys = get_citet_bibkeys(row, \"further_note\")\n",
    "    crossref_bibkeys = get_citet_bibkeys(row, \"crossref\")\n",
    "\n",
    "    depends_on_raw = further_references_raw + further_notes_bibkeys + crossref_bibkeys\n",
    "\n",
    "    return ParsedBibEntry(\n",
    "        id=row.id,\n",
    "        bibkey=row.bibkey,\n",
    "        title=row.title,\n",
    "        notes=row.notes,\n",
    "        crossref=row.crossref,\n",
    "        further_note=row.further_note,\n",
    "        further_references_raw=further_references_raw,\n",
    "        depends_on_raw=depends_on_raw\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_bibkeys(rows: list[INBibEntry]) -> list[str]:\n",
    "\n",
    "    all_bibkeys = [\n",
    "        row.bibkey\n",
    "        for row in rows\n",
    "    ]\n",
    "\n",
    "    return all_bibkeys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bibentry(parsed_bibentry: ParsedBibEntry, all_bibkeys_list: list[str]) -> ProcessedBibEntry:\n",
    "    further_references_good = []\n",
    "    further_references_bad = []\n",
    "    depends_on_good = []\n",
    "    depends_on_bad = []\n",
    "\n",
    "    for bibkey in parsed_bibentry.further_references_raw:\n",
    "        if bibkey in all_bibkeys_list:\n",
    "            further_references_good.append(bibkey)\n",
    "        else:\n",
    "            further_references_bad.append(bibkey)\n",
    "\n",
    "    for bibkey in parsed_bibentry.depends_on_raw:\n",
    "        if bibkey in all_bibkeys_list:\n",
    "            depends_on_good.append(bibkey)\n",
    "        else:\n",
    "            depends_on_bad.append(bibkey)\n",
    "\n",
    "    return ProcessedBibEntry(\n",
    "        id=parsed_bibentry.id,\n",
    "        bibkey=parsed_bibentry.bibkey,\n",
    "        title=parsed_bibentry.title,\n",
    "        notes=parsed_bibentry.notes,\n",
    "        crossref=parsed_bibentry.crossref,\n",
    "        further_note=parsed_bibentry.further_note,\n",
    "        further_references_good=further_references_good,\n",
    "        further_references_bad=further_references_bad,\n",
    "        depends_on_good=depends_on_good,\n",
    "        depends_on_bad=depends_on_bad\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filename: str, encoding: str, output_filename: str) -> None:\n",
    "    rows = load_bibentries_csv(filename, encoding)\n",
    "    parsed_rows = (parse_bibentry(row) for row in rows)\n",
    "    all_bibkeys = get_all_bibkeys(rows)\n",
    "    processed_rows = (process_bibentry(parsed_row, all_bibkeys) for parsed_row in parsed_rows)\n",
    "\n",
    "    with open(output_filename, 'w', encoding=encoding) as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=ProcessedBibEntry.__annotations__.keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows([row.__dict__ for row in processed_rows])\n",
    "    \n",
    "    print(f\"Processed {len(rows)} entries\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bibentry_loop(parsed_bibentry: ParsedBibEntry, all_bibkeys_list: list[str]) -> ProcessedBibEntry:\n",
    "    further_references_good = []\n",
    "    further_references_bad = []\n",
    "    depends_on_good = []\n",
    "    depends_on_bad = []\n",
    "\n",
    "    for bibkey in parsed_bibentry.further_references_raw:\n",
    "        if bibkey in all_bibkeys_list:\n",
    "            further_references_good.append(bibkey)\n",
    "        else:\n",
    "            further_references_bad.append(bibkey)\n",
    "\n",
    "    for bibkey in parsed_bibentry.depends_on_raw:\n",
    "        if bibkey in all_bibkeys_list:\n",
    "            depends_on_good.append(bibkey)\n",
    "        else:\n",
    "            depends_on_bad.append(bibkey)\n",
    "\n",
    "    return ProcessedBibEntry(\n",
    "        id=parsed_bibentry.id,\n",
    "        bibkey=parsed_bibentry.bibkey,\n",
    "        title=parsed_bibentry.title,\n",
    "        notes=parsed_bibentry.notes,\n",
    "        crossref=parsed_bibentry.crossref,\n",
    "        further_note=parsed_bibentry.further_note,\n",
    "        further_references_good=further_references_good,\n",
    "        further_references_bad=further_references_bad,\n",
    "        depends_on_good=depends_on_good,\n",
    "        depends_on_bad=depends_on_bad\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bibentry_lc(parsed_bibentry: ParsedBibEntry, all_bibkeys_list: list[str]) -> ProcessedBibEntry:\n",
    "    further_refs = ((bibkey, 0) if bibkey in all_bibkeys_list else (bibkey, 1) for bibkey in parsed_bibentry.further_references_raw)\n",
    "    depends_on = ((bibkey, 0) if bibkey in all_bibkeys_list else (bibkey, 1) for bibkey in parsed_bibentry.depends_on_raw)\n",
    "\n",
    "    further_references_good = [bibkey for bibkey, status in further_refs if status == 0]\n",
    "    further_references_bad = [bibkey for bibkey, status in further_refs if status == 1]\n",
    "    depends_on_good = [bibkey for bibkey, status in depends_on if status == 0]\n",
    "    depends_on_bad = [bibkey for bibkey, status in depends_on if status == 1]\n",
    "\n",
    "\n",
    "    return ProcessedBibEntry(\n",
    "        id=parsed_bibentry.id,\n",
    "        bibkey=parsed_bibentry.bibkey,\n",
    "        title=parsed_bibentry.title,\n",
    "        notes=parsed_bibentry.notes,\n",
    "        crossref=parsed_bibentry.crossref,\n",
    "        further_note=parsed_bibentry.further_note,\n",
    "        further_references_good=further_references_good,\n",
    "        further_references_bad=further_references_bad,\n",
    "        depends_on_good=depends_on_good,\n",
    "        depends_on_bad=depends_on_bad\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for loops: 106.07913959399957\n",
      "Time for list comprehensions: 76.9970980550006\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "# Define a large dataset for testing\n",
    "parsed_bibentry = ParsedBibEntry(\n",
    "    id=\"1\",\n",
    "    bibkey=\"key1\",\n",
    "    title=\"Title\",\n",
    "    notes=\"Notes\",\n",
    "    crossref=\"Crossref\",\n",
    "    further_note=\"Further Note\",\n",
    "    further_references_raw=[\"key\" + str(i) for i in range(10000)],\n",
    "    depends_on_raw=[\"key\" + str(i) for i in range(10000)]\n",
    ")\n",
    "all_bibkeys_list = [\"key\" + str(i) for i in range(5000)]\n",
    "\n",
    "# Measure the performance of the for loop approach\n",
    "time_for_loops = timeit.timeit(\n",
    "    lambda: process_bibentry(parsed_bibentry, all_bibkeys_list),\n",
    "    number=100\n",
    ")\n",
    "\n",
    "# Measure the performance of the list comprehension approach\n",
    "time_list_comprehensions = timeit.timeit(\n",
    "    lambda: process_bibentry(parsed_bibentry, all_bibkeys_list),\n",
    "    number=100\n",
    ")\n",
    "\n",
    "print(f\"Time for loops: {time_for_loops}\")\n",
    "print(f\"Time for list comprehensions: {time_list_comprehensions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
